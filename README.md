# llm_microservice_with_docker_and_rest_api

A microservice that wraps an LLM model from HuggingFace in a REST API, optionally containerized with Docker.

Tech Stack
Python

Flask or FastAPI

transformers

Docker (optional)

Use Case
Exposing text-generation services via HTTP â€“ for internal bots, testing, or tools.

Why It Matters
Demonstrates the ability to package and serve machine learning tools as infrastructure-ready components.

